---
title: "Group 9 Final Project"
author: "Vinny Dee, Zoe Tuan, Yuchen Mao, Tracy Chen, Jake Li"
date: "10/15/2021"
output: 
  html_document: 
    highlight: tango
    theme: united
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background


#### Our business questions are: 1. What factors are most important in determining employee turnover? and 2. Who leaves based on our predictions? By answering these questions, we can help employers gain an insight into which of the fators affect employee turnover and work on those factors to decrease attrition. Our audience are the employers and the important decision that needs to be made is how to improve employee retention, which they can answer from looking at the eventual results of our model. 


#### Our dataset comes from  https://www.kaggle.com/davinwijaya/employee-turnover, which is a real dataset shared from Edward Babushkin's blog and contains data concerning employee turnover, the length of time the employees have worked for their companies, as well as gender, age, industry, profession, and scores for employee personality traits such as extraversion, anxiety, self-control, or independence. The dataset contains 16 columns and 1129 rows, and we've taken turnover as the response value, while the other columns are treated as predictors. 


#### So far, we have not run into any data cleaning issues. The size of the dataset is manageable, and we have not found any missing or NA values.


#### Employee attrition is an important aspect for all businesses, and finding out which factors attribute most to whether or not an employee is likely to stay with the company is useful for employers everywhere. By having this model and being able to predict which employee's have a high chance of turnover, employers can divert resources to prevent that employee from leaving. It's advantageous to the company, both in conserving time and cost, in recruiting and training new employees if it's possible to maintain the current employee base.

## Analysis

```{r}
turnover <- read.csv("turnover.csv", stringsAsFactors = TRUE, fileEncoding = "latin1")

summary(turnover)

str(turnover)

##As seen in the structure, all data types are correct and thus no additional work is required.

summary(turnover)

##As seen in the summary, our data does not report any missing values, and hence we are done performing an initial clean of our dataset before use.
```

To determine the contributory factors to employee turnover, we can create a number of models and compare any similarities regarding independent variables. 

A second clean of our dataset is in order.
```{r}
#make factors into binary dummy variables and randomize all rows
turnoverMM = as.data.frame(model.matrix(~.-1,turnover)) 

#shuffle rows
set.seed(414)
turnoverMM = turnoverMM[sample(nrow(turnoverMM)),]

#define a normalizing function
normalize = function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

#normalize the data
turnoverNorm = as.data.frame(lapply(turnoverMM, normalize))
```

We now need to create separate testing and training datasets.
```{r}
set.seed(414)
training_indices = sample(1:nrow(turnoverNorm), 0.7*(nrow(turnoverNorm)))

turnover_train = turnoverNorm[training_indices, ]
turnover_test = turnoverNorm[-training_indices, ]
turnover_train_withEvent = turnover_train
turnover_test_withEvent = turnover_test
turnover_train$event = NULL
turnover_test$event = NULL

train_labels = turnoverNorm[training_indices, "event"]
test_labels = turnoverNorm[-training_indices, "event"]
```

The following are a series of baseline models:

### Logistic Regression Analysis
```{r}
library(class)
library(caret)
library(gmodels)

#make the model, remove insignificant elements
logit_model = glm(event ~ . , data = turnover_train_withEvent, family = binomial)
logit_model = step(logit_model, direction = "backward")
summary(logit_model)

#add new column for prediction
turnover_test_copy = turnover_test
turnover_test_copy$pred_glm = 0
turnover_test_copy$pred_glm = predict(logit_model, newdata = turnover_test_copy, type = "response")
turnover_test_copy$pred_glm = ifelse(turnover_test_copy$pred_glm >= 0.5, 1, 0)

#evaluate
CrossTable(x = test_labels, y = turnover_test_copy$pred_glm, prop.chisq = FALSE)
confusionMatrix(as.factor(test_labels), as.factor(turnover_test_copy$pred_glm), positive = "1")
```

The GLM model predicted 167 individuals would leave, of which 112 actually left. It missed 62 who were predicted to stay but actually left. The sensitivity is 64.0% and the specificity is 67.1%. 

After running our logistic regression model using the step function to determine statistically significant predictors, we ended up keeping the following variables:
- Stag (Experience measured in time)
- Industry
- Profession
- Traffic (How the employee got recruited into the company)
- Coach (How much training the employee received)
- Way (How employees travel to work: By foot, bus or car) 
- Independent (Amount of task independence)

Some of the factors that the model eliminated were surprising because we expected factors, such as age, gender, and wage to be significant. Logically, older people, mothers, and workers making low wages have more reason to leave the company or workforce in general but that was not reflected in this model. 

One factor that the model kept that was surprising was traffic because we didn't expect the method at which the employee joined the company to be significant. This might be because people who were recruited with referrals might be more inclined to stay if they knew people already at the company and have a better support network in the organization.

The confusion matrix shows that the model was only had an accuracy of 62%, with high sensitivity of 64% and specificity of 67.1%. To answer our business question of which factor affects attrition, this model was not very useful because it has a high quantity of false negatives, misidentifying many employees left as those who were not at risk of leaving the company.

### Decision Tree

```{r}
library(C50)
turnover_train_withEvent$event <- as.factor(turnover_train_withEvent$event)
dt <- C5.0(event ~., data = turnover_train_withEvent)
turnover_test_copy$pred_dt = predict(dt, turnover_test)

CrossTable(x = test_labels, y = turnover_test_copy$pred_dt, prop.chisq = FALSE)
confusionMatrix(as.factor(test_labels), as.factor(turnover_test_copy$pred_dt), positive = "1")
```



### K Nearest Neighbors Analysis
```{r}
library(class)
library(caret)
library(gmodels)

#choose k to be sqrt of the size
kval = sqrt(nrow(turnover_train))

turnover_test_copy$pred_knn = knn(train = turnover_train, test = turnover_test, cl = train_labels, k = kval)

#convert output from binary factor to numeric
turnover_test_copy$pred_knn = ifelse(turnover_test_copy$pred_knn == "1", 1, 0)

#evaluate
CrossTable(x = test_labels, y = turnover_test_copy$pred_knn, prop.chisq = FALSE)
confusionMatrix(as.factor(test_labels), as.factor(turnover_test_copy$pred_knn), positive = "1")
```
The KNN model predicted 134 individuals would leave, of which 87 actually left. It missed 87 who were predicted to stay but actually left. The sensitivity is 57.6% and the specificity is 64.9%.

### Artificial Neural Network Analysis
```{r}
library(neuralnet)
library(class)
library(caret)
library(gmodels)

ANN_model = neuralnet(event ~ ., data = turnover_train_withEvent, stepmax = 1e+05) #set low for now for testing
ANN_results = compute(ANN_model, turnover_test_withEvent)
turnover_test_copy$pred_ann = ANN_results$net.result
turnover_test_copy$pred_ann = ifelse(turnover_test_copy$pred_ann >= 0.5, 1, 0)

#evaluate
CrossTable(x = test_labels, y = turnover_test_copy$pred_ann, prop.chisq = FALSE)
confusionMatrix(as.factor(test_labels), as.factor(turnover_test_copy$pred_ann), positive = "1")
```

The ANN model predicted 76 individuals would leave, of which 57 actually left. It missed 117 who were predicted to stay but actually left. The sensitivity is 55.5% and the specificity is 75.0%.


### SVM Analysis

```{r}
library(kernlab)
svm_model <- ksvm(event ~ ., data = turnover_train_withEvent, kernel = "vanilladot")
turnover_test_copy$pred_SVM <- predict(svm_model, turnover_test)

CrossTable(x = test_labels, y = turnover_test_copy$pred_SVM, prop.chisq = FALSE)
confusionMatrix(as.factor(test_labels), as.factor(turnover_test_copy$pred_SVM), positive = "1")
```


### Stacked Model
```{r}
# building a decision tree on the five models we produced
combine_df <- data.frame(turnover_test_withEvent$event, turnover_test_copy$pred_glm, turnover_test_copy$pred_knn, turnover_test_copy$pred_ann, turnover_test_copy$pred_dt, turnover_test_copy$pred_SVM)

combine_df

#evaluate
CrossTable(x = test_labels, y = turnover_test_copy$pred_overall, prop.chisq = FALSE)

```

The combined model predicted 124 individuals would leave, of which 88 actually left. It missed 86 who were predicted to stay but actually left. The sensitivity is 60.0% and the specificity is 71.0%.


### Based on models above, are you on track to acheiving your objectives. Are the models helpful on your decision making? How do you need to improve the models?

Of the three models we ran, GLM is currently the highest. This may be due to the ANN being limited in layers (we did this so it would knit faster temporarily), and the KNN not having an optimal k value. GOing forward, we want to find the optimal k-value for KNN and identify the relevant significant variables for GLM. Finally, we will increase the depth of the ANN model so that it returns more accurate results.
